# Monitoramento EnergÃ©tico Sincronizado - ImplementaÃ§Ã£o e Melhores PrÃ¡ticas

## ğŸ¯ VisÃ£o Geral

Este documento descreve as melhorias implementadas no sistema de monitoramento energÃ©tico para fine-tuning de LLMs, com foco em sincronizaÃ§Ã£o precisa e melhores prÃ¡ticas para mediÃ§Ã£o de consumo energÃ©tico.

## ğŸ”§ Principais Melhorias Implementadas

### 1. **Sistema de Callback Sincronizado (`EnergyTrackingCallback`)**

#### Funcionalidades:
- **SincronizaÃ§Ã£o dupla**: MÃ©tricas coletadas tanto por intervalos de tempo (10s) quanto por steps de treinamento
- **Baseline energÃ©tico**: Estabelece consumo base antes do treinamento para cÃ¡lculos diferenciais
- **Callback nativo do Transformers**: IntegraÃ§Ã£o perfeita com o ciclo de vida do treinamento
- **MÃ©tricas de eficiÃªncia**: CÃ¡lculos automatizados de eficiÃªncia energÃ©tica por step

#### Estrutura de Dados:
```python
@dataclass
class EnergyMetrics:
    timestamp: float
    step: int
    epoch: float
    power_avg_w: float
    power_max_w: float
    power_min_w: float
    energy_consumed_wh: float
    temperature_avg_c: float
    temperature_max_c: float
    utilization_avg_percent: float
    memory_used_avg_mb: float
    gpu_name: str
    duration_s: float
    samples_count: int
```

### 2. **Monitor GPU Aprimorado (`RobustGPUMonitor`)**

#### Novas Funcionalidades:
- **Alta precisÃ£o**: Modo de alta precisÃ£o com baseline automÃ¡tico
- **SincronizaÃ§Ã£o por timestamp**: MÃ©todo `get_metrics_since_timestamp()` para cÃ¡lculos incrementais
- **Marcadores de sincronizaÃ§Ã£o**: Sistema para correlacionar eventos do treinamento
- **Consumo diferencial**: SubtraÃ§Ã£o do baseline para mediÃ§Ãµes mais precisas

#### MÃ©todo de Baseline:
```python
def _establish_baseline(self):
    """
    Coleta 5 segundos de dados antes do treinamento comeÃ§ar
    para estabelecer consumo base do sistema
    """
```

### 3. **Logging Estruturado no Wandb**

#### Categorias de MÃ©tricas:

**Por Intervalo de Tempo (10s):**
- `energy_interval/power_avg_w`: PotÃªncia mÃ©dia
- `energy_interval/energy_consumed_wh`: Energia consumida no intervalo
- `energy_interval/efficiency_wh_per_step`: EficiÃªncia energÃ©tica
- `energy_interval/temperature_avg_c`: Temperatura mÃ©dia
- `energy_interval/gpu_utilization_avg_percent`: UtilizaÃ§Ã£o mÃ©dia

**Por Step de Treinamento:**
- `energy_step/power_avg_w`: PotÃªncia no step
- `energy_step/energy_per_step_wh`: Energia por step
- `energy_step/energy_efficiency`: Score de eficiÃªncia calculado
- `energy_step/temperature_avg_c`: Temperatura no step

**MÃ©tricas Finais:**
- `final_energy/total_energy_consumed_kwh`: Consumo total
- `final_energy/energy_per_step_wh`: Energia mÃ©dia por step
- `final_energy/energy_per_epoch_kwh`: Energia mÃ©dia por Ã©poca
- `final_energy/energy_efficiency_score`: Score final de eficiÃªncia
- `final_energy/carbon_footprint_estimate_kg`: Pegada de carbono estimada

## ğŸ“Š Melhores PrÃ¡ticas Implementadas

### 1. **MediÃ§Ã£o Precisa de Energia**

#### Baseline EnergÃ©tico:
- Coleta 5 segundos de dados antes do treinamento
- Subtrai consumo base do sistema operacional e drivers
- Isola o consumo especÃ­fico do treinamento

#### CÃ¡lculo Diferencial:
```python
baseline_adjusted_power = max(0, current_power - baseline_power)
energy_consumed = baseline_adjusted_power * duration_hours
```

### 2. **SincronizaÃ§Ã£o Temporal**

#### Duas EstratÃ©gias Complementares:
1. **Intervalo fixo (10s)**: Garante mediÃ§Ãµes consistentes independente da velocidade do treinamento
2. **Por step**: Permite correlaÃ§Ã£o direta com progresso do modelo

#### Vantagens:
- Dados consistentes para comparaÃ§Ã£o entre experimentos
- CorrelaÃ§Ã£o precisa entre performance e consumo energÃ©tico
- DetecÃ§Ã£o de anomalias ou picos de consumo

### 3. **MÃ©tricas de EficiÃªncia**

#### Score de EficiÃªncia:
```python
def _calculate_energy_efficiency(self, metrics):
    """
    Calcula eficiÃªncia como energia por step ajustada pela utilizaÃ§Ã£o.
    Valores menores = maior eficiÃªncia
    """
    energy_per_step = metrics.energy_consumed_wh / steps_processed
    utilization_factor = metrics.utilization_avg_percent / 100.0
    return energy_per_step / max(0.01, utilization_factor)
```

#### Pegada de Carbono:
```python
def _estimate_carbon_footprint(self, total_energy_kwh):
    """
    Estima CO2 usando fator mÃ©dio global de 0.5 kg CO2/kWh
    """
    return total_energy_kwh * 0.5
```

### 4. **Armazenamento e AnÃ¡lise**

#### MÃºltiplos Formatos:
- **Wandb**: VisualizaÃ§Ã£o em tempo real e anÃ¡lise online
- **JSON local**: Backup e anÃ¡lise offline
- **HistÃ³ricos separados**: Por step e por intervalo para diferentes anÃ¡lises

#### Estrutura de Arquivos:
```
results/
â”œâ”€â”€ energy_step_history_20250728_143022.json
â”œâ”€â”€ energy_interval_history_20250728_143022.json
â”œâ”€â”€ energy_monitoring_summary_20250728_143022.json
â””â”€â”€ robust_gpu_energy_20250728_143022.json
```

## ğŸš€ Como Usar

### 1. **ConfiguraÃ§Ã£o AutomÃ¡tica**
O sistema Ã© ativado automaticamente no `LlamaFineTuner`:

```python
fine_tuner = LlamaFineTuner(wandb_key, hf_token)
trainer = fine_tuner.run_complete_pipeline(dataset_path)
```

### 2. **ConfiguraÃ§Ãµes PersonalizÃ¡veis**

#### Intervalo de SincronizaÃ§Ã£o:
```python
energy_callback = EnergyTrackingCallback(
    gpu_monitor=self.gpu_monitor,
    sync_interval_s=5.0  # Sincronizar a cada 5s
)
```

#### Modo de Alta PrecisÃ£o:
```python
gpu_monitor = RobustGPUMonitor(
    sampling_interval=0.5,  # Amostragem mais frequente
    enable_high_precision=True  # Baseline automÃ¡tico
)
```

### 3. **AnÃ¡lise no Wandb**

#### Dashboard Recomendado:
1. **GrÃ¡fico de linha**: `energy_interval/power_avg_w` vs tempo
2. **Scatter plot**: `energy_step/energy_per_step_wh` vs step
3. **Heatmap**: CorrelaÃ§Ã£o entre temperatura e utilizaÃ§Ã£o
4. **Barras**: ComparaÃ§Ã£o de eficiÃªncia entre Ã©pocas

## ğŸ“ˆ BenefÃ­cios da ImplementaÃ§Ã£o

### 1. **PrecisÃ£o Melhorada**
- Baseline elimina ruÃ­do do sistema operacional
- SincronizaÃ§Ã£o precisa com events do treinamento
- CÃ¡lculos diferenciais mais confiÃ¡veis

### 2. **AnÃ¡lise Detalhada**
- CorrelaÃ§Ã£o direta entre performance e consumo
- IdentificaÃ§Ã£o de ineficiÃªncias por step
- Tracking de tendÃªncias ao longo do treinamento

### 3. **Comparabilidade**
- MÃ©tricas padronizadas entre experimentos
- Intervalos de tempo consistentes
- Scores de eficiÃªncia normalizados

### 4. **Sustentabilidade**
- Estimativa de pegada de carbono
- OtimizaÃ§Ã£o energÃ©tica baseada em dados
- ConsciÃªncia ambiental no desenvolvimento de AI

## ğŸ”® ExtensÃµes Futuras

1. **PrevisÃ£o de Consumo**: Modelos preditivos baseados no histÃ³rico
2. **OtimizaÃ§Ã£o AutomÃ¡tica**: Ajuste de hiperparÃ¢metros para eficiÃªncia
3. **Alertas Inteligentes**: NotificaÃ§Ãµes para consumo anÃ´malo
4. **ComparaÃ§Ã£o de Modelos**: Benchmarks energÃ©ticos automÃ¡ticos
5. **IntegraÃ§Ã£o com Carbon Tracker**: APIs de fatores de emissÃ£o regionais

## ğŸ“ Exemplo de SaÃ­da

```
ğŸ”‹ RELATÃ“RIO ENERGÃ‰TICO FINAL:
â€¢ DuraÃ§Ã£o: 3600s (1.00h)
â€¢ Steps: 1000
â€¢ Ã‰pocas: 3.00
â€¢ Energia total: 0.5500 kWh
â€¢ PotÃªncia mÃ©dia: 550.0W
â€¢ Energia por step: 1.98Wh
â€¢ Energia por Ã©poca: 0.1833kWh
â€¢ Score de eficiÃªncia: 2.1543
â€¢ Pegada de carbono estimada: 0.000275kg CO2
```

Este sistema implementa as melhores prÃ¡ticas atuais para monitoramento energÃ©tico em treinamento de LLMs, proporcionando visibilidade completa sobre o consumo e eficiÃªncia energÃ©tica do processo.
