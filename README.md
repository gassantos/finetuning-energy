# finetuning-energy

Sistema de fine-tuning para modelos de linguagem com foco em eficiÃªncia energÃ©tica para modelos LLMs.

## ğŸš€ Pipeline Integrado

O sistema agora oferece um **pipeline completo automatizado** que inclui:

1. **PrÃ©-processamento de Texto**: Processa dados para formato de sumarizaÃ§Ã£o
2. **Fine-tuning com LoRA**: Ajuste fino eficiente do LLaMA 3.2 3B
3. **Monitoramento EnergÃ©tico**: Rastreamento completo de consumo durante treino

### ExecuÃ§Ã£o Simples

```bash
# Pipeline completo em um comando
uv run python main.py
```

## MÃ³dulos Principais

### ğŸ“Š PrÃ©-processamento de Texto AvanÃ§ado

O sistema inclui um mÃ³dulo robusto de prÃ©-processamento de texto que:

- Processa arquivos (excel) para datasets estruturados de sumarizaÃ§Ã£o
- Oferece limpeza e normalizaÃ§Ã£o de texto
- Cria splits de treino, validaÃ§Ã£o e teste automaticamente
- Valida formato e qualidade dos dados
- Suporta mÃºltiplos formatos de saÃ­da (JSON, Parquet, Arrow)
- CompatÃ­vel com HuggingFace Datasets

### âš¡ Fine-tuning Integrado

O mÃ³dulo de fine-tuning foi atualizado para:

- Aceitar datasets processados localmente
- Manter compatibilidade com datasets HuggingFace
- Detectar automaticamente o formato dos dados
- Aplicar LoRA (Low-Rank Adaptation) para eficiÃªncia
- Monitorar consumo energÃ©tico durante o treino

### ğŸ“ˆ Monitoramento EnergÃ©tico

Sistema robusto de monitoramento energÃ©tico sincronizado que rastreia:

- **Consumo de GPU** (NVIDIA-SMI, PyNVML, nvitop)
- **MÃ©tricas sincronizadas** (a cada 10s + por step de treinamento)
- **Baseline energÃ©tico** (consumo diferencial preciso)
- **EficiÃªncia energÃ©tica** (Wh por step, scores de performance)
- **Pegada de carbono** (estimativa de CO2)
- **Logging estruturado** (Wandb + arquivos locais)

#### Funcionalidades AvanÃ§adas:
- âœ… **SincronizaÃ§Ã£o dupla**: Intervalos fixos + steps de treinamento
- âœ… **Alta precisÃ£o**: Baseline automÃ¡tico para cÃ¡lculos diferenciais  
- âœ… **Callback nativo**: IntegraÃ§Ã£o perfeita com Transformers
- âœ… **MÃ©tricas de eficiÃªncia**: AnÃ¡lise automatizada de performance energÃ©tica
- âœ… **RelatÃ³rios detalhados**: HistÃ³rico completo por step e intervalo
- âœ… **Estimativa de CO2**: ConsciÃªncia ambiental no desenvolvimento


## PrÃ©-processamento de Dados

### Formato de Entrada (Dado Estruturado)
```
| Texto                     | Resumo                   |
| ------------------------- | ------------------------ |
| Texto para sumarizaÃ§Ã£o... | Resumo correspondente... |
```

### Formato de SaÃ­da (HuggingFace)
```json
{
    "text": "Texto original para sumarizaÃ§Ã£o...",
    "summary": "Resumo correspondente..."
}
```

## ğŸ§ª Testes

Sistema completo de validaÃ§Ã£o com **14 testes abrangentes**:

```bash
# Executar todos os testes
uv run pytest

# Testes especÃ­ficos de prÃ©-processamento
uv run pytest tests/test_text_preprocessing_validation.py

# Testes de integraÃ§Ã£o do pipeline
uv run pytest test_pipeline.py

# Executar com verbose
uv run pytest -v
```

### Cobertura de Testes

- âœ… Processamento direto de arquivos Excel
- âœ… Pipeline manual de prÃ©-processamento
- âœ… ValidaÃ§Ã£o de formatos e tipos
- âœ… Tratamento de erros e casos extremos
- âœ… Compatibilidade HuggingFace
- âœ… IntegraÃ§Ã£o completa do pipeline
- âœ… ValidaÃ§Ã£o de configuraÃ§Ã£o
- âœ… Carregamento de datasets processados

## âš™ï¸ ConfiguraÃ§Ã£o

### Arquivos de ConfiguraÃ§Ã£o

O sistema usa `config/settings.toml` para configuraÃ§Ãµes:

```toml
[global]
MODEL_ID = "meta-llama/Llama-3.2-3B"
BATCH_SIZE = 2
LEARNING_RATE = 2e-4
EPOCHS = 3
LORA_R = 8
LORA_ALPHA = 16
DATASET = "billsum"
TASK = "summarization"
QUANTIZATION = "4-bit"
```
OBS.: Para informaÃ§Ãµes sensÃ­veis, recomenda-se o uso de secrets  (`config/.secrets.toml`), conforme Dynaconf.

### Secrets de Ambiente

```bash
# Tokens obrigatÃ³rios para fine-tuning
WANDB_KEY="your_wandb_key"
HF_TOKEN="your_hf_token"
```

## ğŸ“‚ Estrutura do Projeto

```
finetuning-energy/
â”œâ”€â”€ main.py                    # ExecuÃ§Ã£o principal
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ finetuning.py          # Fine-tuning com LoRA
â”‚   â”œâ”€â”€ monitor.py             # Monitoramento energÃ©tico
â”‚   â””â”€â”€ text_preprocessing.py  # PrÃ©-processamento
â”œâ”€â”€ tests/
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ config.py              # ConfiguraÃ§Ãµes
â”‚   â””â”€â”€ settings.toml          # ParÃ¢metros
â””â”€â”€ data/                      # Datasets (local)
```

## ğŸ“Š Exemplo PrÃ¡tico

```bash
# 1. Executar pipeline com monitoramento avanÃ§ado
uv run python main.py

# 2. Monitorar progresso (Weights & Biases)
# Acesse wandb.ai para ver mÃ©tricas em tempo real:
# - energy_interval/*: MÃ©tricas a cada 10s
# - energy_step/*: MÃ©tricas por step de treinamento
# - final_energy/*: RelatÃ³rio final com eficiÃªncia

# 3. Executar exemplos de monitoramento
uv run python examples/energy_monitoring_examples.py
```

### Resultado Esperado
- Dataset processado: `data/processed`
- Modelo fine-tuned: `results/llama_finetuned/`
- **Logs energÃ©ticos sincronizados**: 
  - `results/energy_step_history_*.json`
  - `results/energy_interval_history_*.json`
  - `results/energy_monitoring_summary_*.json`
- **Dashboard W&B com mÃ©tricas avanÃ§adas**:
  - Consumo por step e intervalo
  - Scores de eficiÃªncia energÃ©tica
  - CorrelaÃ§Ã£o performance x energia
  - Estimativa de pegada de carbono

### Executar Testes

```bash
# Todos os testes
uv run pytest

# Apenas testes de validaÃ§Ã£o do prÃ©-processamento
uv run pytest tests/test_text_preprocessing_validation.py -v

# Testes com cobertura
uv run pytest --cov=src
```

## Desenvolvimento

### PrÃ©-requisitos

- Python 3.12+
- [uv](https://docs.astral.sh/uv/getting-started/installation/) (gerenciador de pacotes)


```bash
# Clonar repositÃ³rio
git clone <repo-url>
cd finetuning-energy

# Instalar dependÃªncias
uv sync

# Executar aplicaÃ§Ã£o
uv run python main.py